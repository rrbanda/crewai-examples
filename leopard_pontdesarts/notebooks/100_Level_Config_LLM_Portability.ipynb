{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìå 100-Level: Configuration & Multiple LLM Support\n",
    "\n",
    "This notebook expands on the **beginner** example by introducing:\n",
    "\n",
    "- üîß **Environment-based settings** (via `.env` and `config.yaml`).\n",
    "- ü§ñ **LLM portability** (Support for GPT-4o, Ollama, and MaaS models).\n",
    "- üèóÔ∏è **Better separation of concerns** (No hardcoded API keys or model names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "\n",
    "‚úîÔ∏è Store API keys securely via `.env`.\n",
    "‚úîÔ∏è Use a `config.yaml` to dynamically load agent configurations.\n",
    "‚úîÔ∏è Switch LLM providers dynamically (GPT-4o, Ollama, RH MaaS, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install crewai openai python-dotenv pyyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Setting Up Configuration\n",
    "We'll store our API keys and model settings **outside the code** for security and flexibility."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "ollama_api_key = os.getenv(\"OLLAMA_API_KEY\")\n",
    "\n",
    "# Load Configuration File\n",
    "config_path = \"configs/config.yaml\"\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Extract model details dynamically\n",
    "llm_provider = config.get(\"llm\", {}).get(\"provider\", \"openai\")\n",
    "model_name = config.get(\"llm\", {}).get(\"model_name\", \"gpt-4o\")\n",
    "\n",
    "print(f\"‚úÖ Loaded LLM Provider: {llm_provider}\")\n",
    "print(f\"‚úÖ Using Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Defining a Configurable CrewAI Agent\n",
    "This agent will work with **different models** based on the settings from `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "# Define the AI Agent\n",
    "leopard_agent = Agent(\n",
    "    role=config[\"agent\"][\"role\"],\n",
    "    goal=config[\"agent\"][\"goal\"],\n",
    "    backstory=config[\"agent\"][\"backstory\"],\n",
    "    llm_api_key=openai_api_key if llm_provider == \"openai\" else ollama_api_key,\n",
    "    model=model_name\n",
    ")\n",
    "\n",
    "# Define the Task\n",
    "task = Task(\n",
    "    description=\"How many seconds would it take for a leopard at full speed to run through Pont des Arts?\",\n",
    "    agent=leopard_agent\n",
    ")\n",
    "\n",
    "# Execute the Task\n",
    "crew = Crew(agents=[leopard_agent], tasks=[task])\n",
    "response = crew.kickoff()\n",
    "\n",
    "# Print Response\n",
    "print(\"\\n=== AI Response ===\")\n",
    "print(response.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "‚úîÔ∏è We introduced **environment-based settings** for API keys.\n",
    "‚úîÔ∏è Used a **config.yaml** to dynamically switch AI models.\n",
    "‚úîÔ∏è Separated logic for better maintainability.\n",
    "\n",
    "### **Next Steps:**\n",
    "In **200-Level**, we will introduce **logging, debugging, and agent collaboration**!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
